{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating model performance\n",
    "\n",
    "To be able to confidently tell your model is working, you need concrete metrics that proof that the model is working. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "The confusion matrix can help to see how your model is performing by showing the distribution of the possible outcomes of your target feature. By using the confusion matrix, it is possible to see where your model is performing poorly during classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix visualization**\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Prediction</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Positive</td>\n",
    "        <td>Negative</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Target</td>\n",
    "        <td>Positive</td>\n",
    "        <td>TP</td>\n",
    "        <td>TN</td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>Negative</td>\n",
    "        <td>FP</td>\n",
    "        <td>FN</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**Example for non-binary targets**\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"3\">Prediction</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>High</td>\n",
    "        <td>Medium</td>\n",
    "        <td>Low</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"3\">Target</td>\n",
    "        <td>High</td>\n",
    "        <td>0</td>\n",
    "        <td>5</td>\n",
    "        <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Medium</td>\n",
    "        <td>2</td>\n",
    "        <td>1</td>\n",
    "        <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Low</td>\n",
    "        <td>7</td>\n",
    "        <td>3</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Misclassification Rate** <br />\n",
    "Nr. of incorrect predictions divided by total predictions. The misclassification rate shows the percentage the model was wrong (range [0,1]). \n",
    "\n",
    "$$ rate = { (FP + FN) \\over (TP + TN + FP + FN)} $$\n",
    "\n",
    "**Classification Accuracy** <br />\n",
    "The accuracy shows the percentage of predictions the model was right. Inverting the misclassification rate.\n",
    "\n",
    "$$ accuracy = { (TP + TN) \\over (TP + TN + FP + FN)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical target performance measures\n",
    "**Rates:**<br /> <br />\n",
    "**TPR** = ${ TP \\over TP + FN} $ &nbsp;&nbsp;\n",
    "**FNR** = ${ FN \\over TP + FN} $ &nbsp;&nbsp;\n",
    "**TNR** = ${ TN \\over TN + FP} $ &nbsp;&nbsp;\n",
    "**FPR** = ${ FP \\over TN + FP} $ &nbsp;&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Precision:** ${ TP \\over TP + FP} $ shows how often the model is correct when predicting a positive. <br /><br />\n",
    "**Recall (TPR):** ${ TP \\over TP + FN} $ shows how confident we can be that the model will find all the Positives. <br />\n",
    "\n",
    "**F1 Measure** <br />\n",
    "The F1 measure is the harmonic mean of precision and recall. The F1 measure is good for binary targets and emphasizes the performance on the most important level (positive, is the machine correct with the assumption).\n",
    " $$\\text{F1 Measure} = 2 * {  Precision * Recall \\over Precision + Recall} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Class accuracy:\n",
    "\n",
    "*Good for imbalanced datasets e.g 80/20 distribution on pos/neg target labels.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arithmetic means are susceptible to the influence of large outliers and is a more optimistic view. The harmonic mean emphasizes on smaller values and is a rather pessimistic view. \n",
    "\n",
    "*Arithmetic mean*\n",
    "$$ averageclassaccuracy_{am} = { 1 \\over |levels(t)|} \\sum_{i∈levels(t)} recall(i)$$\n",
    "\n",
    "*Harmonic mean*\n",
    "$$ averageclassaccuracy_{hm} = { 1 \\over {1 \\over levels(t)} \\sum_{i∈levels(t)} {1 \\over recall(i)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
