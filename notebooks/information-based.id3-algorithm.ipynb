{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information-based learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does probability work, e.g. probability per playing card\n",
    "probability_distribution = [1 / 52 for _ in range(52)]   \n",
    "\n",
    "shannon_entropy = -np.sum(probability_distribution * np.log2(probability_distribution))\n",
    "print(f'Total entropy: {round(shannon_entropy, 3)} bits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Util functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataSet wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature: \n",
    "    def __init__(self, D, f):\n",
    "        self._D = D\n",
    "        self._f = f\n",
    "    \n",
    "    def filter(self, l): \n",
    "        return Feature(self._D[self._D[self._f] == l], self._f)\n",
    "    \n",
    "    def IsHomogenous(self) -> bool:\n",
    "        return self._D[self._f].nunique() == 1\n",
    "    \n",
    "    @property\n",
    "    def Mode(self) -> str:\n",
    "        return self._D[self._f].mode().iloc[0]\n",
    "    \n",
    "    @property\n",
    "    def levels(self) -> List[str]:\n",
    "        return self._D[self._f].unique()\n",
    "    \n",
    "    @property\n",
    "    def rows(self) -> int:\n",
    "        return self._D.shape[0]\n",
    "\n",
    "class DataSet:\n",
    "    def __init__(self, D: pd.DataFrame, t: str):\n",
    "        self._D = D\n",
    "        self._t = t\n",
    "\n",
    "    def feature(self, feature) -> Feature: \n",
    "        return Feature(self._D, feature)\n",
    "    \n",
    "    def desc(self, feature) -> Feature: \n",
    "        return Feature(self._D, feature)\n",
    "    \n",
    "    def target(self) -> Feature: \n",
    "        return Feature(self._D, self._t)\n",
    "    \n",
    "    def filter(self, f, l): \n",
    "        return DataSet(self._D[self._D[f] == l], self._t)\n",
    "    \n",
    "    @property\n",
    "    def rows(self) -> int:\n",
    "        return self._D.shape[0]\n",
    "\n",
    "    @property\n",
    "    def df(self): \n",
    "        return self._D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Entropy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(l, f: Feature):\n",
    "    return f.filter(l).rows / f.rows\n",
    "\n",
    "def H(f: str, D: DataSet) -> float:\n",
    "    entropy = lambda P: P * np.log2( P )\n",
    "    \n",
    "    t = D.feature(f)\n",
    "    return -sum([ entropy( P(l, t) ) for l in t.levels])\n",
    "\n",
    "def REM(f: str, desc_feature: str, D: DataSet) -> float: \n",
    "    d = D.feature(desc_feature)\n",
    "    \n",
    "    # sum ( weight of level * entropy of level) \n",
    "    return sum([ P(l, d) * H(f, D.filter(desc_feature, l)) for l in d.levels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Formula's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ['Ace', 'Hearts'], ['Two', 'Hearts'], ['Three', 'Hearts'], ['Four', 'Hearts'], ['Five', 'Hearts'], ['Six', 'Hearts'], ['Seven', 'Hearts'], ['Eight', 'Hearts'], ['Nine', 'Hearts'], ['Ten', 'Hearts'], ['Jack', 'Hearts'], ['Queen', 'Hearts'], ['King', 'Hearts'],\n",
    "    ['Ace', 'Diamonds'], ['Two', 'Diamonds'], ['Three', 'Diamonds'], ['Four', 'Diamonds'], ['Five', 'Diamonds'], ['Six', 'Diamonds'], ['Seven', 'Diamonds'], ['Eight', 'Diamonds'], ['Nine', 'Diamonds'], ['Ten', 'Diamonds'], ['Jack', 'Diamonds'], ['Queen', 'Diamonds'], ['King', 'Diamonds'],\n",
    "    ['Ace', 'Clubs'], ['Two', 'Clubs'], ['Three', 'Clubs'], ['Four', 'Clubs'], ['Five', 'Clubs'], ['Six', 'Clubs'], ['Seven', 'Clubs'], ['Eight', 'Clubs'], ['Nine', 'Clubs'], ['Ten', 'Clubs'], ['Jack', 'Clubs'], ['Queen', 'Clubs'], ['King', 'Clubs'],\n",
    "    ['Ace', 'Spades'], ['Two', 'Spades'], ['Three', 'Spades'], ['Four', 'Spades'], ['Five', 'Spades'], ['Six', 'Spades'], ['Seven', 'Spades'], ['Eight', 'Spades'], ['Nine', 'Spades'], ['Ten', 'Spades'], ['Jack', 'Spades'], ['Queen', 'Spades'], ['King', 'Spades']\n",
    "]\n",
    "\n",
    "playing_cards = pd.DataFrame(data, columns=['Value', 'Category'])\n",
    "\n",
    "D = DataSet(playing_cards, 'Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability per Category\n",
    "P('Clubs', D.feature('Category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy based on a descriptive feature\n",
    "H('Category', D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ID3 Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Entropy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(l, f: Feature):\n",
    "    return f.filter(l).rows / f.rows\n",
    "\n",
    "def H(D: DataSet) -> float:\n",
    "    entropy = lambda P: P * np.log2( P )\n",
    "    t = D.target()\n",
    "    return -sum([ entropy( P(l, t) ) for l in t.levels])\n",
    "\n",
    "def REM(desc_feature: str, D: DataSet) -> float: \n",
    "    d = D.feature(desc_feature)\n",
    "    \n",
    "    # sum ( weight of level * entropy of level) \n",
    "    return sum([ P(l, d) * H(D.filter(desc_feature, l)) for l in d.levels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Tree datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def show(self, indent=0) -> str: \n",
    "        pass\n",
    "    \n",
    "    def predict(self, instance: pd.Series):\n",
    "        pass\n",
    "\n",
    "class Leaf(Node): \n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "\n",
    "    def show(self, indent=0) -> str: \n",
    "        print(f\"{indent*' '}- Leaf: {self.feature}\")\n",
    "\n",
    "    def predict(self, _): \n",
    "        return self.feature\n",
    "\n",
    "class Composite(Node): \n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        self.children: Dict[Any, Node] = {}\n",
    "\n",
    "    def add(self, option, node):\n",
    "        self.children[option] = node\n",
    "\n",
    "    def mode(self, option):\n",
    "        self._mode = option\n",
    "\n",
    "    def show(self, indent=0) -> str: \n",
    "        print(f\"{indent*' '}Node: {self.feature}\")\n",
    "        for option in self.children:\n",
    "            print(f\"{indent*' '}- Option: {option}\")\n",
    "            self.children[option].show(indent+4)\n",
    "\n",
    "    def predict(self, instance: pd.Series): \n",
    "        val = instance[self.feature]\n",
    "        if(val in self.children):\n",
    "            return self.children[val].predict(instance)\n",
    "        else:\n",
    "            return self.children[self._mode].predict(instance)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(d: List[str], D: DataSet) -> Node:\n",
    "     \n",
    "    if(D.rows < 1): \n",
    "        raise Exception(\"DataSet is empty.\") \n",
    "    \n",
    "    if(len(d) < 1): \n",
    "        return Leaf( D.target().Mode )\n",
    "    \n",
    "    if(D.target().IsHomogenous()):\n",
    "        return Leaf( D.target().levels[0] )\n",
    "\n",
    "    MAX_IG = pd.Series(\n",
    "        [ H(D) - REM(f, D) for f in d], \n",
    "        index=d\n",
    "    ).idxmax()\n",
    "\n",
    "    decision_node = Composite(MAX_IG)\n",
    "    \n",
    "    modeDensity = 0\n",
    "    for l in D.df[MAX_IG].unique():\n",
    "        partition = D.filter(MAX_IG, l)\n",
    "\n",
    "        child = D.target().Mode if partition.rows < 1 else ID3(list(filter(lambda l: l != MAX_IG, d)), partition)\n",
    "        decision_node.add(l, child)\n",
    "\n",
    "        pDensity = partition.rows / D.rows\n",
    "        if(pDensity > modeDensity):\n",
    "            decision_node.mode(l)\n",
    "            modeDensity = pDensity\n",
    "\n",
    "    return decision_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spam-ham example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [367,True,False,True,'SPAM'],\n",
    "    [489,True,True,False,'SPAM'],\n",
    "    [541,True,True,False,'SPAM'],\n",
    "    [693,False,True,True,'HAM'],\n",
    "    [782,False,False,False,'HAM'],\n",
    "    [976,False,False,False,'HAM'],\n",
    "] \n",
    "features = ['ID', 'Suspicious words', 'Unknown sender', 'Contains images', 'Class']\n",
    "spam_emails = pd.DataFrame(data, columns=features)\n",
    "\n",
    "spam_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t: str = 'Class'\n",
    "d: List[str] = features[1:4]\n",
    "D: DataSet = DataSet(spam_emails, t='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Gain\n",
    "# IG = H(target_feature, D) - REM(descriptive_feature, D)\n",
    "pd.Series(\n",
    "    [ H(D) - REM(f, D) for f in d], \n",
    "    index=d\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ID3(d, D)\n",
    "tree.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_record = pd.Series({'Suspicious words': True, 'Unknown sender': False, 'Contains images': True})\n",
    "tree.predict(new_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real world dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../datasets/drugs.decision-trees.csv', sep=',', names=[\"Age\",\"Sex\", \"BP\", \"Cholesterol\", \"Na_to_K\", \"Drug\"], header=0)\n",
    "# df['AgeGroup'] = pd.cut(df['Age'], bins=range(10, 80, 5), right=False, labels=False) # age range is between 15 and 74\n",
    "\n",
    "d = [\"Age\", \"Sex\", \"BP\", \"Cholesterol\"]\n",
    "t = 'Drug'\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_cols = [\"Age\", \"AgeGroup\", \"Sex\", \"BP\", \"Cholesterol\"]\n",
    "headers = [\"feature\",\"count\", \"% miss.\", \"card.\", \"Mode\", \"Mode freq.\", \"Mode %\", \"2nd Mode\", \"2nd Mode freq.\", \"2nd Mode %\"]\n",
    "report = []\n",
    "for feature in categorial_cols:\n",
    "    report.append([\n",
    "        feature,\n",
    "        df[feature].size,\n",
    "        df[feature].isnull().sum() / df[feature].size,\n",
    "        df[feature].nunique(),\n",
    "        df[feature].mode().values[0],\n",
    "        df[feature].value_counts().max(),\n",
    "        (df[feature].value_counts().max() / df[feature].size) * 100,\n",
    "        df[feature].value_counts().index[1],\n",
    "        df[feature].value_counts().iloc[1],\n",
    "        (df[feature].value_counts().iloc[1] / df[feature].size) * 100,\n",
    "    ])\n",
    "pd.DataFrame(report, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Drug'].value_counts().plot(kind='bar', title='Drug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real world dataset II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['buying price', 'maintenance cost', 'nr of doors', 'nr of persons', 'lug boot', 'safety', 'decision']\n",
    "df = pd.read_csv('../datasets/car_evaluation.decision-trees.csv', sep=',', names=features, header=0)\n",
    "\n",
    "d = features[:-1]\n",
    "t = 'decision'\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3) \n",
    "\n",
    "D: DataSet = DataSet(train, t)\n",
    "\n",
    "tree = ID3(d, D)\n",
    "test['Pred'] = df.apply(lambda x: tree.predict(x), axis=1)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.1) \n",
    "\n",
    "D: DataSet = DataSet(train, t)\n",
    "\n",
    "tree = ID3(d, D)\n",
    "\n",
    "test['Pred'] = df.apply(lambda x: tree.predict(x), axis=1)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_record = pd.Series({\"AgeGroup\": 47, \"Sex\": \"M\", \"BP\": \"LOW\", \"Cholesterol\": \"HIGH\"})\n",
    "tree.predict(new_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with unique 'Target' levels\n",
    "accuracy_df = pd.DataFrame(test[t].unique(), columns=[t])\n",
    "\n",
    "# Calculate the count of correct and incorrect predictions\n",
    "accuracy_df['Correct'] = accuracy_df[t].apply(lambda x: ((test[t] == x) & (test[t] == x)).sum())\n",
    "accuracy_df['Incorrect'] = accuracy_df[t].apply(lambda x: ((test[t] == x) & (test[t] != x)).sum())\n",
    "accuracy_df['Accuracy'] = round(accuracy_df['Correct'] / (accuracy_df['Correct'] + accuracy_df['Incorrect']),3)\n",
    "\n",
    "accuracy_df.loc[len(accuracy_df.index)] = ['Total', accuracy_df['Correct'].sum(), accuracy_df['Incorrect'].sum(), accuracy_df['Accuracy'].mean()] \n",
    "\n",
    "accuracy_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
