{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability and Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Imports and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature: \n",
    "    def __init__(self, D, f):\n",
    "        self._D = D\n",
    "        self._f = f\n",
    "    \n",
    "    def filter(self, l): \n",
    "        return Feature(self._D[self._D[self._f] == l], self._f)\n",
    "    \n",
    "    def IsHomogenous(self) -> bool:\n",
    "        return self._D[self._f].nunique() == 1\n",
    "    \n",
    "    @property\n",
    "    def Mode(self) -> str:\n",
    "        return self._D[self._f].mode().iloc[0]\n",
    "    \n",
    "    @property\n",
    "    def levels(self) -> List[str]:\n",
    "        return self._D[self._f].unique()\n",
    "    \n",
    "    @property\n",
    "    def rows(self) -> int:\n",
    "        return self._D.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 DataSet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "    def __init__(self, D: pd.DataFrame, t: str):\n",
    "        self._D = D\n",
    "        self._t = t\n",
    "\n",
    "    def feature(self, feature) -> Feature: \n",
    "        return Feature(self._D, feature)\n",
    "    \n",
    "    def desc(self, feature) -> Feature: \n",
    "        return Feature(self._D, feature)\n",
    "    \n",
    "    def target(self) -> Feature: \n",
    "        return Feature(self._D, self._t)\n",
    "    \n",
    "    def filter(self, f, l): \n",
    "        return DataSet(self._D[self._D[f] == l], self._t)\n",
    "    \n",
    "    @property\n",
    "    def rows(self) -> int:\n",
    "        return self._D.shape[0]\n",
    "\n",
    "    @property\n",
    "    def df(self): \n",
    "        return self._D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability is the likelyhood of an event. There are multiple variants of probability: \n",
    "- *Probability:* P(x) = |x| / | all events |\n",
    "- *Joint probability* = | x & y | / | all events |\n",
    "- *Conditional Probability:* P(x|y) = P(x,y) / P(y)\n",
    "\n",
    "You can recalculate a joint probability from a Conditional probability: P(x,y) = P(x|y) x P(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance of getting a single card: 0.019230769230769232\n",
      "Chance of getting a specific suit: 0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "# How does probability work, e.g. probability per playing card\n",
    "print(f\"Chance of getting a single card: {1 / 52}\")\n",
    "print(f\"Chance of getting a specific suit: {1 / 13}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculating entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is the level of impurity or uncertainty in a dataset, it is thecharacteristic in features that ML algorithms will try to minimize. \n",
    "\n",
    "Terminology:\n",
    "- **f** (feature) a column in the dataset\n",
    "- **t** (target feature) the feature we're targeting\n",
    "- **l** (level) a specific value in the feature, like 'Clubs' in Category\n",
    "- **D** (DataSet) the full dataset\n",
    "\n",
    "Functions:\n",
    "- **P** (Probability) The probability function\n",
    "- **H** (Entropy) The entropy function\n",
    "- **REM** (Remaining entropy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entropy: 5.7 bits\n"
     ]
    }
   ],
   "source": [
    "probability_distribution = [1 / 52 for _ in range(52)]   \n",
    "\n",
    "shannon_entropy = -np.sum(probability_distribution * np.log2(probability_distribution))\n",
    "print(f'Total entropy: {round(shannon_entropy, 3)} bits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate entropy by creating a dataset containing every card available in a deck of cards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ['Ace', 'Hearts'], ['Two', 'Hearts'], ['Three', 'Hearts'], ['Four', 'Hearts'], ['Five', 'Hearts'], ['Six', 'Hearts'], ['Seven', 'Hearts'], ['Eight', 'Hearts'], ['Nine', 'Hearts'], ['Ten', 'Hearts'], ['Jack', 'Hearts'], ['Queen', 'Hearts'], ['King', 'Hearts'],\n",
    "    ['Ace', 'Diamonds'], ['Two', 'Diamonds'], ['Three', 'Diamonds'], ['Four', 'Diamonds'], ['Five', 'Diamonds'], ['Six', 'Diamonds'], ['Seven', 'Diamonds'], ['Eight', 'Diamonds'], ['Nine', 'Diamonds'], ['Ten', 'Diamonds'], ['Jack', 'Diamonds'], ['Queen', 'Diamonds'], ['King', 'Diamonds'],\n",
    "    ['Ace', 'Clubs'], ['Two', 'Clubs'], ['Three', 'Clubs'], ['Four', 'Clubs'], ['Five', 'Clubs'], ['Six', 'Clubs'], ['Seven', 'Clubs'], ['Eight', 'Clubs'], ['Nine', 'Clubs'], ['Ten', 'Clubs'], ['Jack', 'Clubs'], ['Queen', 'Clubs'], ['King', 'Clubs'],\n",
    "    ['Ace', 'Spades'], ['Two', 'Spades'], ['Three', 'Spades'], ['Four', 'Spades'], ['Five', 'Spades'], ['Six', 'Spades'], ['Seven', 'Spades'], ['Eight', 'Spades'], ['Nine', 'Spades'], ['Ten', 'Spades'], ['Jack', 'Spades'], ['Queen', 'Spades'], ['King', 'Spades']\n",
    "]\n",
    "\n",
    "playing_cards = pd.DataFrame(data, columns=['Value', 'Suit'])\n",
    "t = 'Suit'\n",
    "\n",
    "D = DataSet(playing_cards, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability\n",
    "The probability function P(l, f) will calculate the probability of a certain level. For example the probability of the suit to be 'Clubs'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Clubs is: 0.25\n"
     ]
    }
   ],
   "source": [
    "def P(l, f: Feature) -> float:\n",
    "    return f.filter(l).rows / f.rows\n",
    "\n",
    "# Probability per Suit\n",
    "f = D.feature('Suit')\n",
    "print(f\"Probability of Clubs is: { P('Clubs', f) }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy function uses the probability function to calculate the entropy of the column. We want our entropy to be as low as possible. \n",
    "\n",
    "```\n",
    "|           n                                    |\n",
    "| H(t,D) = -Σ     ( P(t[l]) x log2(P(t[l])) )    |\n",
    "|           l∈{♣,♦,♥,♠}                          |\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated entropy of 'Suit' is 2.0\n"
     ]
    }
   ],
   "source": [
    "def H(f: str, D: DataSet) -> float:\n",
    "    t = D.feature(f)    \n",
    "\n",
    "    # entropy per level: P(level) x log2(P(level))\n",
    "    entropy_per_level = [ P(l, t) * np.log2( P(l, t) ) for l in t.levels ]\n",
    "    \n",
    "    return -sum(entropy_per_level)\n",
    "\n",
    "# Entropy based on a descriptive feature\n",
    "print(f\"The calculated entropy of 'Suit' is { H('Suit', D) }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remaining entropy\n",
    "The REM function calculates the remaining entropy after a specific feature is used, the ID3 algorithm uses this function to determine which features are most beneficial to put high in the tree. \n",
    "\n",
    "```\n",
    "|                                                   |\n",
    "| REM(d, D) =   Σ ( ( |Dd=i| / |D| ) x H(t, Dd=i) ) |\n",
    "|               i∈levels(d)                         |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated REM after 'Value' is: 1.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "def REM(target_feature: str, desc_feature: str, D: DataSet) -> float: \n",
    "    d = D.feature(desc_feature)\n",
    "    \n",
    "    rem_entropy = 0\n",
    "    for l in d.levels: \n",
    "        rem_entropy += P(l, d) * H(target_feature, D.filter(desc_feature, l))\n",
    "    \n",
    "    # sum ( weight of level * entropy of level) \n",
    "    return rem_entropy\n",
    "\n",
    "print(f\"The calculated REM after 'Value' is: { REM('Suit', 'Value', D) }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Gain\n",
    "Finally, the IG shows the difference between the raw entropy and the information gained by the specific descriptive feature:\n",
    "\n",
    "**Drawback**: Favors features with many levels because the output datasets are very small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Information Gain of 'Value' is: 0.0000000000000004\n"
     ]
    }
   ],
   "source": [
    "def IG(target_feature: str, desc_feature: str, D: DataSet) -> float:  \n",
    "    entropy = H(target_feature, D)\n",
    "    rem = REM(target_feature, desc_feature, D)\n",
    "    return round(entropy - rem, 16)\n",
    "\n",
    "print(f\"The Information Gain of 'Value' is: {IG('Suit', 'Value', D):.16f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative impurity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Gain Ratio\n",
    "dividing the info gain of a feature by the amount of information used to determine the value of the feature.\n",
    "\n",
    "```\n",
    "|                                                           |\n",
    "| GR(d, D) = IG(d, D) / - Σ ( P( d[l] ) x log2(P(d[l])) )   |\n",
    "|                         l∈levels(d)                       |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IGR of 'Value' is: 0.0000000000000001\n"
     ]
    }
   ],
   "source": [
    "def GR(target_feature: str, desc_feature: str, D: DataSet) -> float:  \n",
    "    ig = IG(target_feature, desc_feature, D)\n",
    "    split_info = H(desc_feature, D)\n",
    "    return ig / split_info\n",
    "\n",
    "print(f\"The IGR of 'Value' is: {GR('Suit', 'Value', D):.16f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini index\n",
    "The percentage of misclassified instances if the prediction were made only based on the distribution of the target levels in the dataset. \n",
    "\n",
    "4 instances with eq likelyhood = Gini index of 0.75 = 75% chance of mismatch\n",
    "\n",
    "```\n",
    "|                                      |\n",
    "| GINI(t, D) = 1 - Σ ( P( t[l] )^2 )   |\n",
    "|                  l∈levels(d)         |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GINI(f: str, D: DataSet):\n",
    "    t = D.feature(f) \n",
    "    gini_per_feature = [ P(l, t) ** 2 for l in t.levels ]\n",
    "    return 1-sum(gini_per_feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
