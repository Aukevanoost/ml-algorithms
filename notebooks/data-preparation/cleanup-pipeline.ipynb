{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc3bbb5-3659-445c-89b7-88eac69293e9",
   "metadata": {},
   "source": [
    "# sk_learn Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "84c784f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "78c62288",
   "metadata": {
    "tags": [
     "hide_code",
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "### CUSTOM OUTLIER REMOVAL TRANSFORMERS ###\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "## OUTLIER BASE CLASS\n",
    "class OutlierRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):        \n",
    "        self.columns = columns  \n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X, y=None): \n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame,y=None):\n",
    "        if not self.fitted: raise NotFittedError()\n",
    "        filters = reduce(lambda filter, d: filter & self._append_filter(X, d), self._cols(X), True) \n",
    "        return X.copy()[filters]\n",
    "    \n",
    "    def _cols(self, X: pd.DataFrame): return self.columns or list(X.columns)\n",
    "\n",
    "    def _append_filter(self, X: pd.DataFrame, f: str) -> bool:\n",
    "        min, max = self._range[f]\n",
    "        return (X[f] >= min) & (X[f] <= max)\n",
    "\n",
    "## REMOVE OUTLIERS USING A CUSTOM RANGE (min, max)    \n",
    "class MinMaxOutlierRemover(OutlierRemover):\n",
    "    def __init__(self,range=(0,1), columns=None):\n",
    "        self._threshold = range\n",
    "        super().__init__(columns)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self._range = {f: self._threshold for f in self._cols(X)}\n",
    "        return super().fit(X, y)\n",
    "\n",
    "## REMOVE OUTLIERS USING IQR\n",
    "class IQROutlierRemover(OutlierRemover):\n",
    "    def __init__(self,factor=1.5, columns=None):\n",
    "        self._factor = factor\n",
    "        super().__init__(columns)\n",
    "    \n",
    "    def _find_range(self, X: pd.DataFrame, f: str):\n",
    "        Q1 = X[f].quantile(0.25)\n",
    "        Q3 = X[f].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        return(Q1 - self._factor * IQR, Q3 + self._factor * IQR)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._range = {f: self._find_range(X,f) for f in self._cols(X)}\n",
    "        return super().fit(X, y)\n",
    "\n",
    "\n",
    "## REMOVE OUTLIERS USING Z-SCORE\n",
    "class ZScoreOutlierRemover(OutlierRemover):\n",
    "    def __init__(self, factor=3, columns=None):\n",
    "        self._factor = factor\n",
    "        super().__init__(columns)\n",
    "    \n",
    "    def _find_range(self, X: pd.DataFrame, f: str):\n",
    "        mean = X[f].mean()\n",
    "        sd = X[f].std()\n",
    "        return (mean - sd * self._factor, mean + sd * self._factor)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._range = {f: self._find_range(X,f) for f in self._cols(X)}\n",
    "        return super().fit(X, y)\n",
    "\n",
    "## TRANSFORMATOR TO MERGE AND GROUP VALUES\n",
    "class MergeValues(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, labels, category, columns=None):        \n",
    "        self._from = labels  \n",
    "        self._to = category  \n",
    "        self.columns = columns  \n",
    "        self._fitted = False\n",
    "\n",
    "    def _cols(self, X: pd.DataFrame): return self.columns or list(X.columns)\n",
    "\n",
    "    def fit(self, X, y=None): \n",
    "        self._to = [self._to] if not isinstance(self._to, list) else self._to\n",
    "        self._from = [self._from] if len(self._from) < 1 or not isinstance(self._from[0], list) else self._from\n",
    "        print(self._from)\n",
    "        print(self._to)\n",
    "        if(len(self._from) != len(self._to)): raise ValueError(\"labels size does not match category size\")\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self,X: pd.DataFrame,y=None):\n",
    "        if not self._fitted: raise NotFittedError()\n",
    "        mapc = lambda tags, i: {c: tags[i] for c in self._cols(X)}\n",
    "        return reduce(\n",
    "            lambda D, i: D.replace(to_replace=mapc(self._from, i), value=mapc(self._to, i)),\n",
    "            range(len(self._to)), X\n",
    "        )\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8abf2f",
   "metadata": {},
   "source": [
    "## Using the pipeline to clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "df52e6e5-f109-461c-96ae-2224a577fd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     583\n",
       "ft_income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'ft_income'];\n",
    "df = pd.read_csv('../../datasets/adults.csv', engine='python', sep=', ', names=headers, na_values=['?'])\n",
    "\n",
    "df.head(5)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "7660cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('ft_income',axis=1)\n",
    "y = df['ft_income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42 ) \n",
    "steps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "26dc6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps.extend([\n",
    "    ('IQR outlier removal', IQROutlierRemover(factor=1.5, columns=[\"fnlwgt\", \"hours-per-week\"])),\n",
    "    ('Threshold outlier removal', MinMaxOutlierRemover(range=(0, 30000), columns=[\"capital-gain\"]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "e156676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "continues_tf = [\n",
    "    # (\n",
    "    #     'Continues features', \n",
    "    #     StandardScaler(), \n",
    "    #     ['fnlwgt','capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    # )   \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a25d6-a251-40df-8b0c-58db1c465414",
   "metadata": {},
   "source": [
    "### 1. Categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "c4fad54c-dc1d-44cd-96ef-d42bb8010fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_tf = [\n",
    "    (\n",
    "        'Impute missing workclass', \n",
    "        SimpleImputer(strategy='most_frequent'), \n",
    "        [\"workclass\", \"occupation\", \"native-country\"]\n",
    "    ),\n",
    "    (\n",
    "        'Merge high-school dropouts',\n",
    "        MergeValues(labels=['9th','10th','11th'], category=\"HS-dropout\"),\n",
    "        [\"education\"]\n",
    "    ),\n",
    "    # (\n",
    "    #     'Merge middle-school dropouts',\n",
    "    #     MergeValues(labels=['7th-8th','5th-6th','1st-4th'], category=\"MS-dropout\"),\n",
    "    #     [\"education\"]\n",
    "    # )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e9daa3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['7th-8th', '5th-6th', '1st-4th'], ['9th', '10th', '11th', '12th']]\n",
      "['MS-dropout', 'HS-dropout']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Bachelors', 'Assoc-voc', 'HS-dropout', 'Some-college', 'HS-grad',\n",
       "       'Prof-school', 'Assoc-acdm', 'Masters', 'MS-dropout', 'Doctorate',\n",
       "       'Preschool'], dtype=object)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = MergeValues(\n",
    "    labels=[['7th-8th','5th-6th','1st-4th'], ['9th','10th','11th','12th']], \n",
    "    category=[\"MS-dropout\", \"HS-dropout\"], \n",
    "    columns=[\"education\"]\n",
    ")\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "\n",
    "# print(f\"before: {X_train.shape[0]} rows\")\n",
    "# transformerA = ZScoreOutlierRemover(factor=3, columns=[\"fnlwgt\", \"hours-per-week\"])\n",
    "# X_train = transformerA.fit_transform(X_train)\n",
    "# transformerB = MinMaxOutlierRemover(range=(0, 30000), columns=[\"capital-gain\"])\n",
    "# X_train = transformerB.fit_transform(X_train)\n",
    "# print(f\"after: {X_train.shape[0]} rows\")\n",
    "\n",
    "imputed = pd.DataFrame(X_train, columns=X_train.columns)\n",
    "imputed[\"education\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "2c8c4ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps.append((\n",
    "#     'Scaling data',\n",
    "#     ColumnTransformer( transformers=continues_tf + categorical_tf, remainder='passthrough')\n",
    "# ))\n",
    "\n",
    "# pipeline = Pipeline(steps=steps, verbose=True)\n",
    "\n",
    "# print(f\"before: {X_train.shape[0]} rows\")\n",
    "# clean_data = pipeline.fit_transform(X_train)\n",
    "# print(f\"after: {clean_data.shape[0]} rows\")\n",
    "# print(X_train.shape)\n",
    "# print(clean_data.shape)\n",
    "# pd.DataFrame(clean_data, columns=X_train.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
